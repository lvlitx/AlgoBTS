{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMo7wP3oXoJG7K1bPN3fMwO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6PkYOpp1YP1G"},"outputs":[],"source":["import numpy as np\n"]},{"cell_type":"code","source":["class logisticsRegression():\n","\n","\n","#give the parameters learning rate and no of iterations\n","  def __init__(self,learning_rate, no_of_iterations):\n","    self.learning_rate = learning_rate\n","    self.no_of_iterations = no_of_iterations\n","\n","# fit the function to train the model with dataset\n","\n","  def fit(self,X,Y):\n","    # number of data points in the dataset (number of rows)  -->  m\n","    # number of input features in the dataset (number of columns)  --> n\n","    self.m , self.n = X.shape\n","\n","    #initiate the weights and bias values\n","    self.w = np.zeros(self.n)\n","    self.b = 0\n","    self.X = X\n","    self.Y = Y\n","\n","\n","  #  implementing the gradient descent for optimization\n","\n","\n","    for i in range(self.no_of_iterations):\n","      self.update_weights()\n","    # update the weights and bias using gradient descent\n","\n","    def update_weights(self):\n","      #y_hat formula (sigmoid function)\n","      y_hat =  1 / (1 + np.exp( - (self.X.dot(self.w) + self.b ) ))\n","      # derivaties\n","      dw = (1/self.m)*np.dot(self.X.T, (Y_hat - self.Y))\n","      db = (1/self.m)*np.sum(Y_hat - self.Y)\n","      #updating the weights and bias using gradient descent\n","      self.w = self.w - self.learning_rate * dw\n","      self.b = self.b - self.learning_rate * db\n","\n","\n","    def predict(self , X ):\n","      y_pred = 1 / (1 + np.exp( - (X.dot(self.w) + self.b ) ))\n","      y_pred = np.where( Y_pred > 0.5, 1, 0)\n","      return y_pred"],"metadata":{"id":"lgbz_m3NZSDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0-WfokEwZxFn"},"execution_count":null,"outputs":[]}]}